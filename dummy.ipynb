{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99112e14-1d02-4ad5-be90-9f7193d19d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate synthetic air pollution data (replace with real data if available)\n",
    "num_samples = 1000  # Adjust based on available data\n",
    "no2_values = np.random.uniform(10, 100, num_samples)\n",
    "o3_values = np.random.uniform(10, 100, num_samples)\n",
    "pm25_values = np.random.uniform(5, 200, num_samples)\n",
    "pm10_values = np.random.uniform(10, 300, num_samples)\n",
    "so2_values = np.random.uniform(2, 50, num_samples)\n",
    "co_values = np.random.uniform(0.1, 10, num_samples)\n",
    "\n",
    "# Stack input values for each model\n",
    "input_1 = np.column_stack((no2_values, o3_values))  # NO2 & O3\n",
    "input_2 = pm25_values.reshape(-1, 1)  # PM2.5\n",
    "input_3 = pm10_values.reshape(-1, 1)  # PM10\n",
    "input_4 = np.column_stack((so2_values, co_values))  # SO2 & CO\n",
    "\n",
    "print(\"Synthetic data generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cfb8b68-19f2-4ac0-bf76-c9700636359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 959us/step\n",
      "32/32 [==============================] - 0s 936us/step\n",
      "32/32 [==============================] - 0s 982us/step\n",
      "32/32 [==============================] - 0s 904us/step\n",
      "Predictions from Models 1-4 generated!\n",
      "Shape of X: (1000, 24)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load trained models\n",
    "model_1 = load_model(\"mlp1.keras\")  # NO2 & O3 â†’ Output\n",
    "model_2 = load_model(\"mlp2.keras\")  # PM2.5 â†’ Output\n",
    "model_3 = load_model(\"mlp3.keras\")  # PM10 â†’ Output\n",
    "model_4 = load_model(\"mlp4.keras\")  # SO2 & CO â†’ Output\n",
    "\n",
    "# Get predictions\n",
    "output_1 = model_1.predict(input_1)\n",
    "output_2 = model_2.predict(input_2)\n",
    "output_3 = model_3.predict(input_3)\n",
    "output_4 = model_4.predict(input_4)\n",
    "\n",
    "# Stack all outputs together as input for Model-5\n",
    "X = np.column_stack((output_1, output_2, output_3, output_4))\n",
    "\n",
    "print(\"Predictions from Models 1-4 generated!\")\n",
    "print(f\"Shape of X: {X.shape}\")  # Should be (num_samples, 4) if each model gives one output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b030a16a-782a-45be-9e6b-4603395f6100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final labels generated!\n",
      "Shape of y: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Example: Define pollution categories based on thresholds (customize as needed)\n",
    "def categorize_air_quality(outputs):\n",
    "    pollution_level = np.mean(outputs, axis=1)  # Average all model outputs\n",
    "    categories = np.digitize(pollution_level, bins=[0.2, 0.4, 0.6, 0.8])  # 5 categories (0-4)\n",
    "    return categories\n",
    "\n",
    "y = categorize_air_quality(X)  # Generate labels\n",
    "\n",
    "# Convert to categorical format (if classification)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "\n",
    "print(\"Final labels generated!\")\n",
    "print(f\"Shape of y: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc04b3b3-0c79-47f4-bc9e-38d646c5480b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved successfully! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "np.save(\"final_input_features.npy\", X)\n",
    "np.save(\"final_output_labels.npy\", y)\n",
    "\n",
    "print(\"Training data saved successfully! ðŸŽ‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d52f42-ff60-4abd-bef5-b84cb765b9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data generated and saved!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Number of synthetic samples\n",
    "num_samples = 1000  # You can adjust this\n",
    "\n",
    "# Function to generate synthetic data with noise\n",
    "def generate_data(num_samples, feature_size):\n",
    "    data = np.zeros((num_samples, feature_size))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Randomly activate one of the last two columns (simulating categorical pollution presence)\n",
    "        idx = np.random.choice([4, 5])\n",
    "        data[i, idx] = 1.0\n",
    "\n",
    "        # Add small noise to simulate sensor readings\n",
    "        data[i, :] += np.random.normal(0, 1e-9, size=(feature_size,))\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate synthetic data for each model\n",
    "data_model_1 = generate_data(num_samples, 6)  # NO2 & O3\n",
    "data_model_2 = generate_data(num_samples, 6)  # PM2.5\n",
    "data_model_3 = generate_data(num_samples, 6)  # PM10\n",
    "data_model_4 = generate_data(num_samples, 6)  # SO2 & CO\n",
    "\n",
    "# Convert to DataFrames\n",
    "df1 = pd.DataFrame(data_model_1, columns=[f\"Feature_{i+1}\" for i in range(6)])\n",
    "df2 = pd.DataFrame(data_model_2, columns=[f\"Feature_{i+1}\" for i in range(6)])\n",
    "df3 = pd.DataFrame(data_model_3, columns=[f\"Feature_{i+1}\" for i in range(6)])\n",
    "df4 = pd.DataFrame(data_model_4, columns=[f\"Feature_{i+1}\" for i in range(6)])\n",
    "\n",
    "# Save to CSV (optional)\n",
    "df1.to_csv(\"synthetic_data_model_1.csv\", index=False)\n",
    "df2.to_csv(\"synthetic_data_model_2.csv\", index=False)\n",
    "df3.to_csv(\"synthetic_data_model_3.csv\", index=False)\n",
    "df4.to_csv(\"synthetic_data_model_4.csv\", index=False)\n",
    "\n",
    "print(\"Synthetic data generated and saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
